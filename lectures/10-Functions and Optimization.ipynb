{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation in science\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_007.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you get there? or better,how do you get there without producing a lot of nonsense\n",
    "Counting parameter. e.g. 10 peaks, each position, width, intensity =30 parameter plus background. So fitting is about intelligence. Think, $\\textbf{optimize}$ the smallest amount of parameter starting with a good guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One parameter optimisation (middle = mu)\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/error_way.png\" width=\"1000\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_008.jpg\" width=\"900\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can go into optimisation we have to talk about \n",
    "\n",
    "# Functions:\n",
    "\n",
    "The reason is that you create a function and optimize the parameter of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ways to define functions: the clasical way using def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(s):  #this gives the name of the function. The brackets are mandatory (they do not need to contain anything) colon : is mandatory\n",
    "    print(s) # here needs to be something (what is done in the function) and this needs to be intended\n",
    "my_function('hello world')\n",
    "\n",
    "def my_function(s='input to a function'): #with Standard input that is used if you do not give an input\n",
    "    print(s)\n",
    "my_function()\n",
    "\n",
    "def my_function(s=None,a=['get','a','second','input']): #multiple input\n",
    "    s=1  #inside the function you can use whatever variable you have given, and you can do to it whatever you want. If you have the same variable outside the function this will not be altered (namespace)\n",
    "    return a # and a function can return something if it returns multipe things with \"return a,b\"  then the call must be c,d=my_function() \n",
    "catching_the_return = my_function('hello world')\n",
    "' '.join(catching_the_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second way to create a function is with something called Lambda Functions. They are usually used if you need the function only once (e.g. when you want to plot it) and are useful for e.g. curve_fit (comes next) or for changing things in DataFrames with the df.apply approach (comes later) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: (x-x.min())/(x.max()-x.min())\n",
    "line = lambda x,p: p[0]+p[1]*x\n",
    "x=np.arange(-2,5,0.1)\n",
    "y=line(x,[1,3])\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a standard function that takes x, mu and sigma and returns a gaussian bell curve (with normalisation). Make sure that you use numpy operations only, so that you can give it a vector and receive a vector.<br> \n",
    "${\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}\\operatorname {exp} \\left(-{\\frac {\\left(x-\\mu \\right)^{2}}{2\\sigma ^{2}}}\\right)$\n",
    "* plot this function with mu=0,sigma=1 from -5 to 5 in 0.01 steps \n",
    "\n",
    "* Write a lambda function that returns the normalized vector \n",
    "* use the cumsum function from numpy to create the cummulative sum of the gaussian from above and normalize it with your lambda function\n",
    "* Plot this in the same plot (against x)\n",
    "* What does this resemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimisation: Fitting vs. optimisation\n",
    "\n",
    "\n",
    "## Curve Fit\n",
    "Starting with curve_fit. We assume that we have a flat function that has a clear gradient to the minimum (see top of this page) then we can use curve_fit to fast measure the parameter we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = lambda x,mu=0,sigma=1,offset=0: 1/np.sqrt(2*np.pi*(sigma**2))*np.exp((-0.5/sigma**2)*(np.subtract(x,mu))**2)+offset\n",
    "                                    \n",
    "#create some data with some randomness and plot it\n",
    "x=np.linspace(-5,5,200)\n",
    "y=gauss(x,mu=0.5,sigma=0.5)+0.1*np.random.random(np.shape(x))\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(x,y,'o',ms=2,label='data')\n",
    "ax.set_xlabel('measured value')\n",
    "ax.set_ylabel('occurance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "#make a guess\n",
    "p0=[1,1,0.1]\n",
    "\n",
    "#optimise\n",
    "popt,pcov = curve_fit(gauss, xdata=x, ydata=y,p0=p0)\n",
    "\n",
    "#plot both\n",
    "ax.plot(x, gauss(x, mu=p0[0],sigma=p0[1],offset=p0[2]), 'b-', label='guess')\n",
    "ax.plot(x, gauss(x, mu=popt[0],sigma=popt[1],offset=popt[2]), 'r-', label='fit')\n",
    "ax.legend()\n",
    "\n",
    "#get errors from the covariance matrix (works here, but careful)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "df=pd.DataFrame({'values':popt,'errors':perr},index=['$\\mu$','$\\sigma$','$x_0$'])\n",
    "df=df[['values','errors']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key bit\n",
    "```\n",
    "from scipy.optimize import curve_fit\n",
    "popt,pcov = curve_fit(gauss, xdata=x, ydata=y,p0=[1,0.5,0.1])\n",
    "```\n",
    "curve fit is a least square method that takes a function, the target data and a set of starting parameters, that are in order the parameter after the first.\n",
    "it returns: \n",
    "popt = optimized parameter\n",
    "and\n",
    "pcov = covariance matrix.\n",
    "p_sigma = np.sqrt(np.diag(pcov))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_009.jpg\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "Read the file, Fit the file, plot both, data and fits:\n",
    "What is the center position of the peak\n",
    "http://www.jensuhlig.de/Kemm30/fit_0.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy minimize\n",
    "\n",
    "Second way of optimisation uses in addition to the \"cost function\" an \"error function\". The task of the second function is to create a \"price\" for this parameter. The Minimize function is then minimizing this price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x,p): #the function that is your model\n",
    "    [mu,sigma,offset]=p\n",
    "    pre_factor=1/np.sqrt(2*np.pi*(sigma**2))\n",
    "    exponent=(-0.5/sigma**2)*(np.subtract(x,mu))**2\n",
    "    return pre_factor*np.exp(exponent)+offset\n",
    "x=np.linspace(-5,5,200)\n",
    "y=gauss(x,[0.5,0.5,0.2])\n",
    "y=y+(y**0.5)*0.5*np.random.random(np.shape(x))\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.plot(x,y,'o',ms=5,label='data')\n",
    "ax.set_xlabel('measured value')\n",
    "ax.set_ylabel('occurance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new thing is that you need a second function that produces you a single \"error\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gauss(p):# this would be the root mean square (we skip the root as the minimum is the minimum)\n",
    "    return ((y-gauss(x,p))**2).sum()\n",
    "def min_gauss_lin(p): #this is a different cost function that uses a more linear approach. It does not \"punish\" strong deviations as much. As such it has the tendency to be more outlier stable but preforms bad for peaks.\n",
    "    return np.abs(y-gauss(x,p)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize #import the minimization function\n",
    "x0=[1.,0.5,0.1]\n",
    "out = minimize(min_gauss,x0=x0,method='Nelder-Mead') #nelder-Mead is a standard multi-parameter optimiser. check out other choices.\n",
    "out2 = minimize(min_gauss_lin,x0=x0,method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,8))\n",
    "ax.plot(x,y,'o',ms=5,label='data')\n",
    "ax.set_xlabel('measured value')\n",
    "ax.set_ylabel('occurance')\n",
    "ax.plot(x, gauss(x, p=x0), color='blue',lw=5,alpha=0.5,label='start')\n",
    "ax.plot(x, gauss(x, p=out['x']), color='red',linestyle='dashed', lw=5,label='fit_sqrt')\n",
    "ax.plot(x, gauss(x, p=out2['x']), color='green',lw=5,zorder=0, label='fit_lin')\n",
    "print(out)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "Read the files, Fit files and plot both, data and fits:\n",
    "* http://www.jensuhlig.de/Kemm30/fit_0.csv\n",
    "* http://www.jensuhlig.de/Kemm30/fit_1.csv  here: try first a separate fit, in which you fit the linear range and then separately the peak.\n",
    "* http://www.jensuhlig.de/Kemm30/fit_3.csv (two peaks and background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the peaks\n",
    "\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/2D_measured_indicated.png\" width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced\n",
    "\n",
    "While scipy minimize is a very useful tool, it is still a bit difficult to handle parameters. A very nice tool that was developed for this lmfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "def gauss_with_names(x,par): #the function that is your model\n",
    "    pre_factor=1/np.sqrt(2*np.pi*(par['sigma']**2))\n",
    "    exponent=(-0.5/par['sigma']**2)*(np.subtract(x,par['mu']))**2\n",
    "    return pre_factor*np.exp(exponent)+par['offset']\n",
    "def min_gauss(par,x,y):# this would be the root mean square (we skip the root as the minimum is the minimum)\n",
    "    return ((y-gauss_with_names(x,par))**2).sum()\n",
    "\n",
    "x=np.linspace(-5,5,200)\n",
    "y=gauss(x,[0.5,0.5,0.2])\n",
    "y=y+(y**0.5)*0.5*np.random.random(np.shape(x))\n",
    "\n",
    "\n",
    "#first create a parameter object\n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "\n",
    "par.add('mu',value=0,vary=True)                                # Add a parameter\n",
    "par.add('sigma',value=0.5,vary=True)\n",
    "par.add('offset',value=0.1,vary=True)\n",
    "\n",
    "mini = lmfit.Minimizer(min_gauss,par,fcn_kws={'x':x,'y':y})\n",
    "results = mini.minimize('nelder')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
