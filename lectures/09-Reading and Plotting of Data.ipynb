{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib qt5\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make operating with large and variable data more comfortable a number of special libraries have been developed. One important one is Pandas. Pandas has 2 main objects, a series (pretty much an x and y vector stacked together) and a DataFrame (pretty much an x vector stacked together with many y-vectors). For us of important use is the import function, that has many options (confusing in the beginning) but that once learned offers pretty much a universal solution for reading and writing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas in itself is a neat little tool to visualize and manipulate dictionary like objects. Lets look on our Cookbook from above again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cookbook={'pancakes':{\n",
    "                    'description':'delicious food prepared fast',\n",
    "                    'receipe':{'eggs':2,'milk':1,'flour':500,'sugar':1},\n",
    "                    'time(min)':10.0\n",
    "    \n",
    "                     },\n",
    "        'chocolade icecream':{\n",
    "                    'description':'my favourite cholate icecream receipe',\n",
    "                    'receipe':{'frozen fruit':2,'yoghurt/Afil':1,'vanilie sugar':1,'sugar':1},\n",
    "                    'Process':'Blend i Mixer'\n",
    "                                }\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert it to DataFrame and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Cookbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single column DataFrame is called a series, which is its own class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Cookbook['pancakes']['receipe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neat thing is the \"named adressing of data\". So if the contents of a group are of one type I can do a lot of useful things with it. Lets put only the receipies in a DataFrame. We start by creating a Dictionary that contains what we want and then convert it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ingredience={} # empty dictionary\n",
    "\n",
    "for recept in Cookbook.keys(): # loop over the receipies\n",
    "    Ingredience[recept]=Cookbook[recept]['receipe']\n",
    "Ingredience=pd.DataFrame(Ingredience) #create the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ingredience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ingredience  # Notebook make a nicer print for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ingredience.sum(axis='columns') # there are a lot of useful functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use data_frame_name=pd.read_csv() to read your datafile. with index_col=0 you define which column contains your x-data. With header=None. you tell it that your file has no column names. with sep=';' you tell it what separator to use. plot the resulting dataframe with data_frame_name.plot() you can open the file in Jupyter or notebook or gedit or any text editor to figure out what type of separator you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the reading you can give the columns and the index a name. figure out how this works. If you have multiple columns you might have to use e.g. a list of names, one for each column.\n",
    "\n",
    "Read the data in \" http://www.jensuhlig.de/Kemm30/sinc.dat \". For this you can either open the file directly from the internet or (simplier) download it into your working directory first. Play with the options until you get the X-value in the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the file can be tricky if they contain a lot of data see what df.head() and df.tail() show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but usually a good way to inspect a file is to plot it. once you have a dataframe df then df.plot() is the simplest and convenient way to create an overview plot. test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv( \"http://www.jensuhlig.de/Kemm30/sinc.dat\",index_col=0)\n",
    "df.columns.name='scale'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe give the columns a general name with df.columns.name='scale' and plot it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries of the columns or index can be accessed with df.columns.values or df.index.values\n",
    "The type of one of these entries are strings by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.columns.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If strings is what you would like to sort then this is fine, otherwise we can \n",
    "convert the type of the data in the columns into e.g. real numbers with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=df.columns.values.astype(float)\n",
    "df.index=df.index.values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sort we can the columns (and only the columns) and plot it again. (hint check which axis you are sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries are often the easiest way to create and name DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timen=np.arange(0,60,0.1)\n",
    "dicten={}\n",
    "for rate in np.arange(1,10,1):\n",
    "    dicten['%i'%rate]=np.exp(-timen/rate)\n",
    "df=pd.DataFrame(dicten,index=timen)\n",
    "df.index.name='time [s]'\n",
    "df.columns.name='rate [mol/s]'\n",
    "df.plot()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to load and handle many datafiles we should quickly look into how to handle directories. \n",
    "Loading a file from a sub directory needs the filesystem separator. the package os.sep provides this platform independent (on linux and windows alike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='data\\\\sinc.dat' #problem is the folder separator that is specific to operational system\n",
    "import os #ignore for now\n",
    "filename=os.sep.join(['data','sinc.dat']) #easy to read and independent of which platform\n",
    "#Now filename contains the name of the file and the directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a sub directory, move the file in there and open/plot it. Usually one separates data from the analysis files to keep order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes your file contains already the names of the columns and it is most comfortable to read it all at once.\n",
    "\n",
    "### Task\n",
    "\n",
    "In this file the column names contain the with of the scaling factor and shall be read automatically. Use the x-value as index. Read and plot (with labels) the data in \" http://www.jensuhlig.de/Kemm30/sinc_2.dat \". The column names contain the with of the scaling factor and shall be read automatically. Use the x-value as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "The data file \" http://www.jensuhlig.de/Kemm30/APS_Copper_SolarCell.dat \" was measured at a large scale research facility: the \"Advanced light source\" in Chicago and represents X-ray absorption data. Ignore the first 30 rows (and header) and read all columns from the file. Hint the separator \"\\s+\" separate for one or multiple white spaces.\n",
    "\n",
    "Use copy paste to extract the column names (Row 30) from the text file and paste it in your Notebook as a long string. Then use the string method \"split\" to separate the string into a list of column names and give the columns in the DataFrame the right name. This can be done during the import or afterwards.\n",
    "\n",
    "The Column \"Energy\" shall be used as index. Plot column \"PR\" vs \"Energy\". In Pandas the columns are named and the easiest way to do this is to use the column name. so if df=pd.read_csv('filename') read in your file and you have chose the right options then with df[\"PR\"].plot() you plot only one column. If you notice, the \"Energy\" column is now only the index and not a separate column anymore. \n",
    "\n",
    "The easiest way to achieve this is either count the columns or use the name of the column to define the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulation, this is most likely one of the most difficult files you ever need to read, combining all the techniques you have learned up to now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names='N  Epoch  Energy  k  Mono  Seconds  ion1  ion2  ion3  ion4  mud  mud1  mostabc  SYNM  PR  bun-1  bun-1GS  bun1  bun1GS  bun2  bun2GS  DifSYN  Difb_1  Difb1  Difb2  c0o0b0  c0o1b0  c0o2b0  c0o3b0  c0o4b0  c0o5b0  c0o6b0  c0o7b0  c0o8b0  c0o9b0  c0o10b0  c0o11b0  c0o12b0  c0o13b0  c0o14b0  c0o15b0  c0o16b0  c0o17b0  c0o18b0  c0o19b0  c0o20b0  c0o21b0  c1o0b0  c1o1b0  c1o2b0  c1o3b0  c1o4b0  c1o5b0  c1o6b0  c1o7b0  c1o8b0  c1o9b0  c1o10b0  c1o11b0  c1o12b0  c1o13b0  c1o14b0  c1o15b0  c1o16b0  c1o17b0  c1o18b0  c1o19b0  c1o20b0  c1o21b0  c2o0b0  c2o1b0  c2o2b0  c2o3b0  c2o4b0  c2o5b0  c2o6b0  c2o7b0  c2o8b0  c2o9b0  c2o10b0  c2o11b0  c2o12b0  c2o13b0  c2o14b0  c2o15b0  c2o16b0  c2o17b0  c2o18b0  c2o19b0  c2o20b0  c2o21b0  c3o0b0  c3o1b0  c3o2b0  c3o3b0  c3o4b0  c3o5b0  c3o6b0  c3o7b0  c3o8b0  c3o9b0  c3o10b0  c3o11b0  c3o12b0  c3o13b0  c3o14b0  c3o15b0  c3o16b0  c3o17b0  c3o18b0  c3o19b0  c3o20b0  c3o21b0'\n",
    "col_names=col_names.split()\n",
    "print('print the first 8 entries: {}'.format(col_names[:8]))\n",
    "df3=pd.read_csv(\"http://www.jensuhlig.de/Kemm30/APS_Copper_SolarCell.dat\",skiprows=30,sep='\\s+',names=col_names,index_col='Energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are automatic ways how to do this column extraction:\n",
    "The first method only reads the columns you want and reduces the work, but requires me to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3a=pd.read_csv(\"http://www.jensuhlig.de/Kemm30/APS_Copper_SolarCell.dat\",skiprows=30,sep='\\s+',names=['Energy','PR'],index_col=0,usecols=[2,14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method uses an escape character to extract the column names automatically and allows then the use of the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b=pd.read_csv(\"http://www.jensuhlig.de/Kemm30/APS_Copper_SolarCell.dat\",skiprows=29,escapechar='L',sep='\\s+',index_col=0,usecols=['Energy','PR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we can plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,4))\n",
    "df3b.plot(ax=ax2)#here we plot all\n",
    "df3['PR'].plot(ax=ax1)#here we plot only the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas slicing\n",
    "Pandas is a powerfull library for data Processing. Beside its strong import function it has a bunch of statistical modules and most important special, value based indexing, sorting and filtering and plotting.\n",
    "\n",
    "A whole bunch of tutorials for Pandas are available online:<br>\n",
    "https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html<br>\n",
    "or<br>\n",
    "https://dataanalysispython.readthedocs.io/en/latest/index.html<br>\n",
    "\n",
    "While challenging at first it is worth digging into the structure as it is very convenient for handling data and the quasi standard. <br>\n",
    "\n",
    "imports come from csv or excel sheets or the internet. powerful filtering techniques can be applied to get rid of missing data or outliers. We use for now the indexing methods we learned for numpy but now using pandas indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas indexing, 2 types:\n",
    "\n",
    "df.loc[\"name of row\",\"name of column\"] \"name based indexing\"<br>\n",
    "df.iloc[1:5,3:5] \"index based indexing (pretty much like numpy)\"<br>\n",
    "df.index #extract the index as a vector\n",
    "\n",
    "Lets look on an example. We use the DataFrame from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timen=np.arange(0,60,0.1)\n",
    "dicten={}\n",
    "for rate in np.arange(1,10,1):\n",
    "    dicten['%i'%rate]=np.exp(-timen/rate)\n",
    "df=pd.DataFrame(dicten,index=timen)\n",
    "df.index.name='time [s]'\n",
    "df.columns.name='rate [mol/s]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select only the times between 10s and 20s one can then simply choose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[10.01:20.04,:].plot() #I choose here a uneven cut to show that we do not have to hit an actually excisting value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one can understand the DataFrame as a fancy dictionary and add e.g. new columns by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[10]=np.exp(-timen/rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "\n",
    "Create the a DataFrame with position from -5 cm to 5 cm as the index and in the columns different gaussians bell curves <br>\n",
    "${\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}\\operatorname {exp} \\left(-{\\frac {\\left(x-\\mu \\right)^{2}}{2\\sigma ^{2}}}\\right)$<br>\n",
    "with the same central position (mu=0) and different width sigma (0.5,1,2,3,4)\n",
    "using the simplified plotting from above to show them in the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does plotting actually mean? <br>\n",
    "import matplotlib.pyplot as plt <br>\n",
    "[Matplotlib backends](https://matplotlib.org/tutorials/introductory/usage.html#backends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#standard plotting\n",
    "plt.plot(np.arange(-5,5,0.01),np.sin(2*np.pi*np.arange(-5,5,0.01)))\n",
    "plt.xlim((-4,4)) # the order matters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### before changing the backend you have to restart the kernel (under Kernel/Restart & clear output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook  \n",
    "#interactives and powerfull backend\n",
    "plt.ion()  #interactives plotting\n",
    "plt.plot(np.arange(-5,5,0.01),np.sin(2*np.pi*np.arange(-5,5,0.01)))\n",
    "plt.xlim((-4,4)) # the order matters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "#interactives and externes plotting. using the qt platform, most powerfull if qt is installed\n",
    "plt.plot(np.arange(-5,5,0.01),np.sin(2*np.pi*np.arange(-5,5,0.01)))\n",
    "plt.xlim((-4,4)) # the order matters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a plot has a Frame = Figure = The window \n",
    "and what is plotted on it = the axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a plot consist of?\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_006.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matlab style plotting $\\leftrightarrow $ Object style plotting, why make it more complicate?\n",
    "our convention: we use matlab type plotting for quick convenience and the object type for everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get handle afterwards method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.gcf() #get current figure\n",
    "ax=plt.gca() #get current axis\n",
    "ax=fig.get_axes() #get all axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the get handle before method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()  #want to use options?\n",
    "ax=fig.add_subplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lazy combine both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots() #single axis\n",
    "fig,(ax1,ax2)=plt.subplots(1,2) #\n",
    "fig,ax=plt.subplots(2,1) # multiple axis as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "x=np.arange(0,4,0.01)\n",
    "ax.plot(x,np.sin(2*np.pi*x))\n",
    "ax.set_xlim(-2,4)\n",
    "plt.show()#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ticks manual\n",
    "ax.set_xticks(np.arange(0,4,0.5))\n",
    "\n",
    "#set ticks manual\n",
    "a=ax.get_xticks()\n",
    "ax.set_xticklabels(['%.2f'%b for b in a])\n",
    "\n",
    "#set axis label\n",
    "_=ax.set_xlabel('schniffdiff')\n",
    "\n",
    "#legend\n",
    "leg=ax.legend(frameon=False,loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cheat sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should I ever remember all of this? $\\rightarrow$ you get used to it or you look it up/use a cheat sheet <br>\n",
    "https://python-graph-gallery.com/wp-content/uploads/Matplotlib_cheatsheet_datacamp.png      <br>\n",
    "Or look in the folder Cheat cheats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here a way to make the general fonts bigger\n",
    "import matplotlib\n",
    "font = {'family' : 'Arial Unicode MS',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 24}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot sinus and cosine in the same plot.<br>\n",
    "* Plot with two different RBG colours chose from the university colours see e.g. <br>\n",
    "    http://www.jensuhlig.de/Lund_university_inkscape.gpl\n",
    "  Important RGB colours are usually given as numbers between 0 and 255, but matplotlib wants numbers between 0 and 1.<br>\n",
    "  so rgb_arry=np.array([0,0,188])/255. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some statistics to get interesting data for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For learning how to make propper plots we start with an experiment in statistics <br>\n",
    "we want to measure what is the average number of dots shown by a dice <br>\n",
    "This returns a single dice throw (test it a few times to see how it changes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.choice([1,2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a vector with 100 dice throws:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.choice([1,2,3,4,5,6],size=(100))\n",
    "print(x.shape)\n",
    "print('The mean of 100 dice throws is:{}'.format(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this will create a matrix with 1000x 100 dice throws in x\n",
    "and then we calculate for y the mean for each of the 1000 set of 100 throws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.choice([1,2,3,4,5,6],size=(100,1000))\n",
    "print(x.shape)\n",
    "y=x.mean(axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fontsize 18 and make a figure with 14x14 inch size using the pre handle option from above\n",
    "* use subplots to make two horizontal plots over the whole width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read what np.histogram does, The function returns the \"edges\" of the bins and the counts in each bin. Why are they of different length? Classically one takes the middle of the bins to create  nice plot with <br>\n",
    "middle_bins=(bins[:-1]+bins[1:])/2<br>\n",
    "* create a vector that contains the bins from 0 to 7 in 0.05 steps, calculate the histrogram and catch its two output vectors\n",
    "* plot the histogram using a bar plot with grey bars in the second axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* plot in the second axis a gaussian function with mu=y.mean() of all experiments, and is sigma=standard_deviation(with ddof=1) of all experiments. and multiply the gaussian with 50. Why does this match so well?\n",
    "* label all the x- and y scales \n",
    "* change the x-axis from 2.5 to 4.5\n",
    "* format the x-axis ticks to have precisely 2 after comma digits\n",
    "* format the y-axis in scientific notation (using exponents)\n",
    "* make a legend in the upper left corner. in the legend write the entries and colors you plotted\n",
    "* find a way to add extra text to the legend and write the parameters of the gaussian curve into the plot (not the legend!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'Arial Unicode MS',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 16}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The final figure will look like this, we have plotted the first half for now\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/first_half.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a scatterplot into the second axis where each experiment of 100 throws is a single point. <br>\n",
    "The x-coordinate is the mean of the 100 throws = y. <br>\n",
    "The y-coordinate is for each point randomly chosen between 0 and the height of the gaussian. <br>\n",
    "np.random.rand() gives [0-1). if you multiply it with the gaussian heigth calculated before you can achieve this effect.<br>\n",
    "height=np.random.rand(np.shape(y)[0])*gauss(x=y,mu=y.mean(),sigma=y.std())\n",
    "* use markersize 2 for this plot\n",
    "* don't forget to label the axis and make a legend (use bbox_to_anchor to place it somewhere proper)\n",
    "* Save the resulting figure as png with 250dpi and as svg for further customisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced:\n",
    "* In this scatterplot, plot all points inside the one sigma environment (=1/2 std diviation) of the mean in blue and all outside in red.\n",
    "* hint: you can externally create a \"slicing vector\" by e.g. a=x>5 and combine multiple of thos with e.g np.all\n",
    "* write in the legend in addition to the colour the total number of counts in each group. (hint, use sum on t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final figure will look like this\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/second_half.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I throw a dice 100 times then in 68% of all cases the \"real value\" will be within the standard diviation of the data assuming that the data is normal distributed (like most measurements) often this is used as \"error\" of the measurement. for large number of discrete throws of dices this works, because of the:\n",
    "https://en.wikipedia.org/wiki/Central_limit_theorem\n",
    "\n",
    "We speak about the experiment (discrete value) and the model (the gaussian or normal distributed data). So the discrete model in fact says: If I throw my dice 100 times I will most likely get something around 350 as the sum of these throws and with 68% probability my result will lay within $350\\pm 15$.\n",
    "\n",
    "Looking into this webpage you will find that this spread of the data can be estimated by the variance of the experiment.\n",
    "Remember the standard deviation was defined as $\\sqrt{\\frac{\\sum_n{x_i - \\bar x}^2}{n-1}}$ carefully, there are two $\\sqrt{\\frac{\\sum_n{x_i - \\bar x}^2}{n}}$\n",
    "\n",
    "As a wild guess, the average is somewhere in the middle, so $\\frac{1+6}{2}=3.5$ is the mean and $2.5^2 + 2.5^2$ the total width. Or \n",
    "\n",
    "$\\bar x \\pm std(x)/2$ \n",
    "\n",
    "is your confidence interval\n",
    "\n",
    "Important to remember: the variance is the 65% environment. To be more sure people often use the \"two sigma environment\" which then contains 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error bar plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.jensuhlig.de/Kemm30/data_with_error.csv\"\n",
    "data=pd.read_csv(url,sep='\\t',index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(16,4))\n",
    "x=data.index\n",
    "y=data.iloc[:,0]\n",
    "yerr=data.iloc[:,1]\n",
    "ax[0].errorbar(x=x,y=y,yerr=yerr,fmt='o',capsize=3)\n",
    "ax[1].plot(x, y,color='black')\n",
    "ax[1].fill_between(x,y-yerr,y+yerr,facecolor='grey',edgecolor='face',alpha=0.5)\n",
    "ax[0].set_xlabel('time[s]');ax[1].set_xlabel('time[s]')\n",
    "ax[0].set_ylabel(r'log($1-\\frac{Abs}{Abs_{inf}}$)');ax[1].set_ylabel(r'log($1-\\frac{Abs}{Abs_{inf}}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:\n",
    "In the dice throws above we could draw a gaussian function over the histogram of the dice throws. For each point we are actually uncertain about where it actually is. classically one uses a poisson estimator to evaluate how certain we are about the intensity at this point. So for each point of gaus(x) we can use $\\sqrt{gauss(x)}$ as an error bar. <br>\n",
    "Replace the gauss curve in the plot above with a point by point calculation using error bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D plotting\n",
    "\n",
    "2d plotting (as 3d plotting) means that you have to create coordinate information for each point of you matrix. so the first point need (1,1,z(1,1)) and so on. There are many ways how to do this, but np.meshgrid is a usual and fast way. Observe the difference between pcolormesh and imshow. The point is that a mesh is more than an image. It really has an axis that can be distorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot a gaussian in 2d\n",
    "x=np.arange(-5,5,0.1)\n",
    "X,Y=np.meshgrid(x,x)\n",
    "def gauss2d(X,Y,mu=(0,0),sigma=(1,1)):\n",
    "    scale=(sigma[0]+sigma[1])*(2*np.pi)\n",
    "    expo=(X-mu[0])**2/(-2*sigma[0]**2)+(Y-mu[1])**2/(-2*sigma[1]**2)\n",
    "    return np.e**expo/scale\n",
    "Z=gauss2d(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].imshow(Z)\n",
    "ax[1].pcolormesh(X,Y,Z,cmap='viridis')\n",
    "ax[2].pcolor(X,Y,Z,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "create a sinodual wave. In the x-dimension the function follows a sinus. In y-dimension it follows a gaussian.\n",
    "Hint: check np.tile and np.outer for help\n",
    "plot this wave in 2d in a suitable region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced: There are other libraries that provide you with interactive 2d/3d plots. This is one of the useful ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "ax= fig.add_subplot(projection='3d')\n",
    "surf=ax.plot_surface(X,Y,Z,cmap='jet',antialiased=False)\n",
    "ax.contourf(X, Y, Z, zdir='z',offset=-0.05, cmap='jet')\n",
    "ax.contourf(X, Y, Z, zdir='x',offset=-5,cmap='jet')\n",
    "ax.contourf(X, Y, Z, zdir='y',offset=5, cmap='jet')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "ax.set_zlim3d(-0.05,0.06)\n",
    "ax.set_xlabel('x-axis',labelpad=15)\n",
    "ax.set_ylabel('y-axis',labelpad=15)\n",
    "ax.set_zlabel('z-axis',labelpad=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
